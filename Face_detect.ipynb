{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d370b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,time\n",
    "import cv2\n",
    "import pyttsx3   #offline lib for tts\n",
    "import serial  #for serial communication with arduino\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12e7cd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\hp\\appdata\\roaming\\python\\python37\\site-packages (4.7.0.68)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\hp\\anaconda3\\envs\\machinevision\\lib\\site-packages (from opencv-contrib-python) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-contrib-python --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f10294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade=cv2.CascadeClassifier('C:\\\\Users\\\\HP\\\\anaconda3\\\\envs\\\\machinevision\\\\Lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_alt2.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read('trainedModel.yml')  # Reading the stored trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc02adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiallize speech engine\n",
    "engine = pyttsx3.init() \n",
    "\n",
    "#Loading the label-id relation to get the name of the labels.\n",
    "with open(\"label_ids.pickle\",'rb') as fr:    \n",
    "    og_labels=pickle.load(fr)\n",
    "\n",
    "#labels are of the form {name:id} we want to invert this form to {id:name}\n",
    "labels={k:v for v,k in og_labels.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "701d7d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'jamila', 1: 'luai'}\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "# face_cascade=cv2.CascadeClassifier('haarcascade_profileface.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1fc501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 86.25381494122635\n",
      "PREDICTED :  jamila\n",
      "0 86.40387851418646\n",
      "PREDICTED :  jamila\n",
      "0 87.14096678810972\n",
      "PREDICTED :  jamila\n",
      "0 87.31672066682208\n",
      "PREDICTED :  jamila\n",
      "0 86.85339428123763\n",
      "PREDICTED :  jamila\n",
      "0 87.36578770541433\n",
      "PREDICTED :  jamila\n",
      "0 85.5954385211128\n",
      "PREDICTED :  jamila\n",
      "0 87.45037211554848\n",
      "PREDICTED :  jamila\n",
      "0 86.42025038304423\n",
      "PREDICTED :  jamila\n",
      "0 86.42133755778698\n",
      "PREDICTED :  jamila\n",
      "0 84.84342308400822\n",
      "PREDICTED :  jamila\n",
      "0 85.59333417228228\n",
      "PREDICTED :  jamila\n",
      "0 85.64471300177757\n",
      "PREDICTED :  jamila\n",
      "0 89.03629401118833\n",
      "PREDICTED :  jamila\n",
      "0 86.29813558873126\n",
      "PREDICTED :  jamila\n",
      "0 86.56412523845823\n",
      "PREDICTED :  jamila\n",
      "0 86.90486054038301\n",
      "PREDICTED :  jamila\n",
      "DOOR is OPEN\n"
     ]
    }
   ],
   "source": [
    "def speak(text):  #fn to convert text to speech\n",
    "    engine.say(text)\n",
    "    engine.runAndWait() \n",
    "\n",
    "def face_recognition():\n",
    "    flag_face_recognised=False   #to keep track if the user face is recognized\n",
    "    flag_face_not_recognised=False\n",
    "\n",
    "    no_of_adjacent_prediction=0\n",
    "    no_face_detected=0  #to track the number of times the face is detected\n",
    "    prev_predicted_name=''   #to keep track of the previously predicted face(w.r.t frame)\n",
    "    cap=cv2.VideoCapture(0)\n",
    "    count_frames = total_no_face_detected = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    while True:\n",
    "        count_frames+=1\n",
    "        ret,frame = cap.read()\n",
    "        # print(ret,frame)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces=face_cascade.detectMultiScale(gray,scaleFactor=1.2,minNeighbors=5)\n",
    "\n",
    "        # print(\"FACES : \",faces)\n",
    "        # print(type(frame))   #The frames are automatically converted into numpy arrays of pixels.\n",
    "        for (x,y,w,h) in faces:\n",
    "\n",
    "            total_no_face_detected+=1\n",
    "            no_face_detected+=1\n",
    "\n",
    "            # print(x,y,w,h)\n",
    "            roi_gray=gray[y:y+h,x:x+w]  #roi(region of interest)\n",
    "            # roi_color=frame[y:y+h,x:x+w]\n",
    "            id,confidence=recognizer.predict(roi_gray)\n",
    "            print(id,confidence)\n",
    "            if(confidence>70):\n",
    "                print(\"PREDICTED : \",labels[id])\n",
    "                font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "                name=labels[id]\n",
    "                clr=(255,255,255);thickness=2\n",
    "                cv2.putText(frame,name.replace('_',' ').title(),(x,y-5),font,0.8,clr,1,cv2.LINE_AA)\n",
    "\n",
    "            \n",
    "                if(prev_predicted_name==name):\n",
    "                    no_of_adjacent_prediction+=1\n",
    "                else:\n",
    "                    no_of_adjacent_prediction=0\n",
    "\n",
    "                prev_predicted_name=name        \n",
    "\n",
    "\n",
    "\n",
    "            # color=(255,0,0) #BGR 0-255\n",
    "            thickness=1\n",
    "            end_coord_x=x+w\n",
    "            end_coord_y=y+h\n",
    "\n",
    "\n",
    "            if(no_of_adjacent_prediction>15):   #no_of_adjacent_prediction is only updated when the confidence of classification is >80\n",
    "                cv2.putText(frame,\"Welcome home \"+name.replace('_',' ').title(),(160,460),font,0.8,clr,thickness,cv2.LINE_AA)  #to print on frame\n",
    "                flag_face_recognised=True\n",
    "                no_of_adjacent_prediction=0\n",
    "                no_face_detected=0\n",
    "\n",
    "            elif(no_face_detected>=30):\n",
    "                cv2.putText(frame,\"Face Not Recognised\",(160,460),font,0.8,clr,thickness,cv2.LINE_AA)\n",
    "                flag_face_not_recognised=True\n",
    "                no_of_adjacent_prediction=0\n",
    "                no_face_detected=0\n",
    "\n",
    "            cv2.rectangle(frame,(x,y),(end_coord_x,end_coord_y),(0,0,0),2)  #Drawing the rectangle on the frame\n",
    "\n",
    "        cv2.imshow('Face Recognition',frame)\n",
    "\n",
    "        if(flag_face_recognised):    #if face is recognized then open the door\n",
    "            speak(\"Welcome \"+name.replace('_',' ')+\", unlocking door. The door will remain open for the next 5 seconds\")\n",
    "            print(\"DOOR is OPEN\")\n",
    "            #arduino.write(bytes('o', 'utf-8'))  #Output the given byte string over the serial port.\n",
    "            \n",
    "            time.sleep(5)\n",
    "            speak(\"Closing door\")\n",
    "            #arduino.write(bytes('c', 'utf-8'))  #Output the given byte string over the serial port.\n",
    "            print(\"DOOR is CLOSED\")\n",
    "            flag_face_recognised=False\n",
    "\n",
    "        if(flag_face_not_recognised):\n",
    "            speak(\"Face not recognised. The door will remain closed\")    \n",
    "            time.sleep(2)\n",
    "            flag_face_not_recognised=False\n",
    "\n",
    "\n",
    "        k=cv2.waitKey(20)     #the key is recieved and converted into ascii value\n",
    "        if k==113:  #compairing with the ordinal/ascii value of 'q'\n",
    "            break\n",
    "\n",
    "\n",
    "    print(\"No. of frames : \",count_frames,\" |   No. of times face detected : \",total_no_face_detected)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if(__name__==\"__main__\"):\n",
    "    face_recognition()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20655bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
